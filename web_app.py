#!/usr/bin/env python3
"""
è§†é¢‘è´¨é‡è¯„ä¼°å·¥å…· - Web ç•Œé¢

ä½¿ç”¨ Streamlit æ„å»ºçš„äº¤äº’å¼ç•Œé¢ï¼Œæ”¯æŒï¼š
- é…ç½®ç¼–ç å‚æ•°
- è¿è¡Œè¯„ä¼°
- å±•ç¤ºç»“æœæ›²çº¿å›¾
"""

import json
import os
import subprocess
import sys
import time
from pathlib import Path
from typing import Any

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

from benchmark import (
    ENCODERS,
    BenchmarkResult,
    load_results,
    run_single_benchmark,
    save_results,
)


st.set_page_config(
    page_title="è§†é¢‘è´¨é‡è¯„ä¼°å·¥å…·",
    page_icon="ğŸ¬",
    layout="wide",
)

st.title("ğŸ¬ è§†é¢‘è´¨é‡è¯„ä¼°å·¥å…·")
st.markdown("è‡ªåŠ¨åŒ–è§†é¢‘ç¼–ç å’Œ VMAF è´¨é‡è¯„ä¼°")


def get_existing_results() -> list[str]:
    """è·å–å·²æœ‰çš„ç»“æœæ–‡ä»¶"""
    results_dir = Path("results")
    if not results_dir.exists():
        return []
    
    result_files = []
    for subdir in results_dir.iterdir():
        if subdir.is_dir():
            results_json = subdir / "results.json"
            if results_json.exists():
                result_files.append(str(results_json))
    
    return result_files


def results_to_dataframe(results: list[BenchmarkResult]) -> pd.DataFrame:
    """å°†ç»“æœè½¬æ¢ä¸º DataFrame"""
    data = []
    for r in results:
        encoder_config = ENCODERS.get(r.encoder, None)
        encoder_name = encoder_config.name if encoder_config else r.encoder
        row = {
            "ç¼–ç å™¨": encoder_name,
            "ç¼–ç å™¨ID": r.encoder,
            "å‚æ•°å": r.param_name,
            "å‚æ•°å€¼": r.param_value,
            # VMAF æŒ‡æ ‡
            "VMAF å¹³å‡": r.vmaf_mean,
            "VMAF æœ€å°": r.vmaf_min,
            "VMAF æœ€å¤§": r.vmaf_max,
            # PSNR-HVS æŒ‡æ ‡
            "PSNR-HVS å¹³å‡": getattr(r, 'psnr_hvs_mean', 0),
            "PSNR-HVS æœ€å°": getattr(r, 'psnr_hvs_min', 0),
            "PSNR-HVS æœ€å¤§": getattr(r, 'psnr_hvs_max', 0),
            # SSIM æŒ‡æ ‡
            "SSIM å¹³å‡": getattr(r, 'ssim_mean', 0),
            "SSIM æœ€å°": getattr(r, 'ssim_min', 0),
            "SSIM æœ€å¤§": getattr(r, 'ssim_max', 0),
            # MS-SSIM æŒ‡æ ‡
            "MS-SSIM å¹³å‡": getattr(r, 'ms_ssim_mean', 0),
            "MS-SSIM æœ€å°": getattr(r, 'ms_ssim_min', 0),
            "MS-SSIM æœ€å¤§": getattr(r, 'ms_ssim_max', 0),
            # SNR æŒ‡æ ‡
            "SNR å¹³å‡ (dB)": getattr(r, 'snr_mean', 0),
            "SNR æœ€å° (dB)": getattr(r, 'snr_min', 0),
            "SNR æœ€å¤§ (dB)": getattr(r, 'snr_max', 0),
            # åŸºæœ¬ä¿¡æ¯
            "æ–‡ä»¶å¤§å° (MB)": r.output_size_mb,
            "å‹ç¼©æ¯” (%)": r.compression_ratio,
            "ç¼–ç è€—æ—¶ (ç§’)": r.encode_time_seconds,
        }
        data.append(row)
    return pd.DataFrame(data)


# å®šä¹‰å¯ç”¨çš„æŒ‡æ ‡é€‰é¡¹
METRIC_OPTIONS = {
    "VMAF": {"col": "VMAF å¹³å‡", "min_col": "VMAF æœ€å°", "max_col": "VMAF æœ€å¤§", "range": [0, 100], "format": ".2f"},
    "PSNR-HVS": {"col": "PSNR-HVS å¹³å‡", "min_col": "PSNR-HVS æœ€å°", "max_col": "PSNR-HVS æœ€å¤§", "range": None, "format": ".2f"},
    "SSIM": {"col": "SSIM å¹³å‡", "min_col": "SSIM æœ€å°", "max_col": "SSIM æœ€å¤§", "range": [0, 1], "format": ".4f"},
    "MS-SSIM": {"col": "MS-SSIM å¹³å‡", "min_col": "MS-SSIM æœ€å°", "max_col": "MS-SSIM æœ€å¤§", "range": [0, 1], "format": ".4f"},
    "SNR": {"col": "SNR å¹³å‡ (dB)", "min_col": "SNR æœ€å° (dB)", "max_col": "SNR æœ€å¤§ (dB)", "range": None, "format": ".2f"},
}


def plot_metric_vs_param(df: pd.DataFrame, metric_name: str = "VMAF"):
    """
    ç»˜åˆ¶æŒ‡æ ‡ vs å‚æ•°å€¼ æ›²çº¿å›¾
    
    Args:
        df: æ•°æ®æ¡†
        metric_name: æŒ‡æ ‡åç§° (VMAF, PSNR-HVS, SSIM, MS-SSIM, SNR)
    """
    metric_config = METRIC_OPTIONS.get(metric_name, METRIC_OPTIONS["VMAF"])
    col = metric_config["col"]
    min_col = metric_config["min_col"]
    max_col = metric_config["max_col"]
    y_range = metric_config["range"]
    
    fig = px.line(
        df,
        x="å‚æ•°å€¼",
        y=col,
        color="ç¼–ç å™¨",
        markers=True,
        title=f"è´¨é‡å‚æ•° vs {metric_name} åˆ†æ•°",
        labels={"å‚æ•°å€¼": "è´¨é‡å‚æ•°å€¼", col: f"{metric_name} åˆ†æ•°"},
    )
    
    # æ·»åŠ è¯¯å·®èŒƒå›´ï¼ˆå¦‚æœåˆ—å­˜åœ¨ä¸”æœ‰æœ‰æ•ˆå€¼ï¼‰
    if min_col in df.columns and max_col in df.columns:
        for encoder in df["ç¼–ç å™¨"].unique():
            encoder_df = df[df["ç¼–ç å™¨"] == encoder]
            if encoder_df[min_col].sum() > 0:  # åªåœ¨æœ‰æ•°æ®æ—¶æ·»åŠ 
                fig.add_trace(go.Scatter(
                    x=encoder_df["å‚æ•°å€¼"],
                    y=encoder_df[min_col],
                    mode="lines",
                    line=dict(width=0),
                    showlegend=False,
                    hoverinfo="skip",
                ))
                fig.add_trace(go.Scatter(
                    x=encoder_df["å‚æ•°å€¼"],
                    y=encoder_df[max_col],
                    mode="lines",
                    line=dict(width=0),
                    fill="tonexty",
                    fillcolor="rgba(0,100,80,0.1)",
                    showlegend=False,
                    hoverinfo="skip",
                ))
    
    layout_update = {
        "xaxis_title": "è´¨é‡å‚æ•°å€¼ (crf)",
        "yaxis_title": f"{metric_name} åˆ†æ•°",
        "legend_title": "ç¼–ç å™¨",
    }
    if y_range:
        layout_update["yaxis_range"] = y_range
    
    fig.update_layout(**layout_update)
    
    return fig


def plot_vmaf_vs_param(df: pd.DataFrame):
    """ç»˜åˆ¶ VMAF vs å‚æ•°å€¼ æ›²çº¿å›¾ï¼ˆå‘åå…¼å®¹ï¼‰"""
    return plot_metric_vs_param(df, "VMAF")


def plot_vmaf_vs_size(df: pd.DataFrame):
    """ç»˜åˆ¶ VMAF vs æ–‡ä»¶å¤§å° æ›²çº¿å›¾"""
    fig = px.scatter(
        df,
        x="æ–‡ä»¶å¤§å° (MB)",
        y="VMAF å¹³å‡",
        color="ç¼–ç å™¨",
        size="å‹ç¼©æ¯” (%)",
        hover_data=["å‚æ•°å€¼", "å‹ç¼©æ¯” (%)"],
        title="æ–‡ä»¶å¤§å° vs VMAF åˆ†æ•°",
    )
    
    # ä¸ºæ¯ä¸ªç¼–ç å™¨æ·»åŠ è¿çº¿
    for encoder in df["ç¼–ç å™¨"].unique():
        encoder_df = df[df["ç¼–ç å™¨"] == encoder].sort_values("æ–‡ä»¶å¤§å° (MB)")
        fig.add_trace(go.Scatter(
            x=encoder_df["æ–‡ä»¶å¤§å° (MB)"],
            y=encoder_df["VMAF å¹³å‡"],
            mode="lines",
            line=dict(dash="dot"),
            showlegend=False,
            hoverinfo="skip",
        ))
    
    fig.update_layout(
        xaxis_title="æ–‡ä»¶å¤§å° (MB)",
        yaxis_title="VMAF åˆ†æ•°",
        yaxis_range=[0, 100],
        legend_title="ç¼–ç å™¨",
    )
    
    return fig


def plot_compression_efficiency(df: pd.DataFrame):
    """ç»˜åˆ¶å‹ç¼©æ•ˆç‡å›¾ (VMAF / å‹ç¼©æ¯”)"""
    df_copy = df.copy()
    df_copy["æ•ˆç‡"] = df_copy["VMAF å¹³å‡"] / df_copy["å‹ç¼©æ¯” (%)"]
    
    fig = px.bar(
        df_copy,
        x="å‚æ•°å€¼",
        y="æ•ˆç‡",
        color="ç¼–ç å™¨",
        barmode="group",
        title="å‹ç¼©æ•ˆç‡ (VMAF / å‹ç¼©æ¯”)",
        labels={"æ•ˆç‡": "æ•ˆç‡åˆ†æ•°", "å‚æ•°å€¼": "è´¨é‡å‚æ•°å€¼"},
    )
    
    fig.update_layout(
        xaxis_title="è´¨é‡å‚æ•°å€¼",
        yaxis_title="æ•ˆç‡åˆ†æ•° (è¶Šé«˜è¶Šå¥½)",
        legend_title="ç¼–ç å™¨",
    )
    
    return fig


def plot_quadrant(df: pd.DataFrame):
    """
    ç»˜åˆ¶å››è±¡é™å›¾ï¼šVMAF åˆ†æ•° vs å‹ç¼©æ¯”
    
    - X è½´ï¼šå‹ç¼©æ¯”ï¼ˆ%ï¼‰ï¼Œè¶Šä½è¶Šå¥½ï¼ˆæ–‡ä»¶è¶Šå°ï¼‰
    - Y è½´ï¼šVMAF åˆ†æ•°ï¼Œè¶Šé«˜è¶Šå¥½
    - ç†æƒ³åŒºåŸŸï¼šå·¦ä¸Šè§’ï¼ˆä½å‹ç¼©æ¯” + é«˜ VMAFï¼‰
    """
    # è®¡ç®—åˆ†å‰²çº¿çš„é˜ˆå€¼
    vmaf_threshold = 90  # VMAF 90 åˆ†ä½œä¸ºé«˜è´¨é‡é˜ˆå€¼
    compression_threshold = df["å‹ç¼©æ¯” (%)"].median()  # ä½¿ç”¨ä¸­ä½æ•°ä½œä¸ºå‹ç¼©æ¯”é˜ˆå€¼
    
    # åˆ›å»ºæ ‡ç­¾åˆ—ï¼Œç”¨äºæ˜¾ç¤ºå‚æ•°å€¼
    df_copy = df.copy()
    df_copy["æ ‡ç­¾"] = df_copy.apply(
        lambda r: f"{r['å‚æ•°å']}={r['å‚æ•°å€¼']}", axis=1
    )
    
    # åˆ›å»ºæ•£ç‚¹å›¾
    fig = px.scatter(
        df_copy,
        x="å‹ç¼©æ¯” (%)",
        y="VMAF å¹³å‡",
        color="ç¼–ç å™¨",
        text="æ ‡ç­¾",
        size_max=15,
        hover_data={
            "å‚æ•°å€¼": True,
            "æ–‡ä»¶å¤§å° (MB)": ":.2f",
            "VMAF æœ€å°": ":.2f",
            "VMAF æœ€å¤§": ":.2f",
            "æ ‡ç­¾": False,
        },
        title="å››è±¡é™å›¾ï¼šè´¨é‡ vs å‹ç¼©æ¯”",
    )
    
    # è°ƒæ•´æ–‡æœ¬ä½ç½®
    fig.update_traces(
        textposition="top center",
        textfont_size=10,
        marker=dict(size=12),
    )
    
    # è·å–åæ ‡è½´èŒƒå›´
    x_min, x_max = df_copy["å‹ç¼©æ¯” (%)"].min(), df_copy["å‹ç¼©æ¯” (%)"].max()
    x_padding = (x_max - x_min) * 0.1
    
    # æ·»åŠ æ°´å¹³åˆ†å‰²çº¿ï¼ˆVMAF é˜ˆå€¼ï¼‰
    fig.add_hline(
        y=vmaf_threshold,
        line_dash="dash",
        line_color="gray",
        annotation_text=f"VMAF {vmaf_threshold}",
        annotation_position="right",
    )
    
    # æ·»åŠ å‚ç›´åˆ†å‰²çº¿ï¼ˆå‹ç¼©æ¯”é˜ˆå€¼ï¼‰
    fig.add_vline(
        x=compression_threshold,
        line_dash="dash",
        line_color="gray",
        annotation_text=f"å‹ç¼©æ¯” {compression_threshold:.1f}%",
        annotation_position="top",
    )
    
    # æ·»åŠ å››è±¡é™æ ‡æ³¨
    annotations = [
        # å·¦ä¸Šï¼šæœ€ä½³åŒºåŸŸ
        dict(
            x=x_min + x_padding,
            y=95,
            text="âœ… æœ€ä½³<br>(é«˜è´¨é‡+é«˜å‹ç¼©)",
            showarrow=False,
            font=dict(size=12, color="green"),
            bgcolor="rgba(0,255,0,0.1)",
        ),
        # å³ä¸Šï¼šé«˜è´¨é‡ä½†æ–‡ä»¶å¤§
        dict(
            x=x_max - x_padding,
            y=95,
            text="âš ï¸ è´¨é‡å¥½ä½†æ–‡ä»¶å¤§",
            showarrow=False,
            font=dict(size=12, color="orange"),
            bgcolor="rgba(255,165,0,0.1)",
        ),
        # å·¦ä¸‹ï¼šå‹ç¼©å¥½ä½†è´¨é‡å·®
        dict(
            x=x_min + x_padding,
            y=75,
            text="âš ï¸ æ–‡ä»¶å°ä½†è´¨é‡å·®",
            showarrow=False,
            font=dict(size=12, color="orange"),
            bgcolor="rgba(255,165,0,0.1)",
        ),
        # å³ä¸‹ï¼šæœ€å·®åŒºåŸŸ
        dict(
            x=x_max - x_padding,
            y=75,
            text="âŒ æœ€å·®<br>(ä½è´¨é‡+å¤§æ–‡ä»¶)",
            showarrow=False,
            font=dict(size=12, color="red"),
            bgcolor="rgba(255,0,0,0.1)",
        ),
    ]
    
    fig.update_layout(
        xaxis_title="å‹ç¼©æ¯” (%) - è¶Šä½è¶Šå¥½ â†",
        yaxis_title="VMAF åˆ†æ•° - è¶Šé«˜è¶Šå¥½ â†‘",
        yaxis_range=[min(60, df_copy["VMAF å¹³å‡"].min() - 5), 100],
        legend_title="ç¼–ç å™¨",
        annotations=annotations,
    )
    
    return fig


AUTOTUNE_TASK_KEY = "autotune_task"
VIDEO_EXTENSIONS = {".mp4", ".mov", ".mkv", ".avi", ".m4v", ".webm"}


def discover_videos(directory: str) -> list[str]:
    path = Path(directory).expanduser()
    if not path.exists() or not path.is_dir():
        return []
    videos = [p for p in path.iterdir() if p.is_file() and p.suffix.lower() in VIDEO_EXTENSIONS]
    return sorted(str(p) for p in videos)


def tail_file(path: str, lines: int = 80) -> str:
    file_path = Path(path)
    if not file_path.exists():
        return ""
    with file_path.open("r", encoding="utf-8", errors="replace") as f:
        content = f.readlines()
    return "".join(content[-lines:])


def extract_marker(path: str, marker: str) -> str | None:
    text = tail_file(path, lines=200)
    for line in reversed(text.splitlines()):
        if line.startswith(marker):
            return line.split(":", 1)[1].strip()
    return None


def get_existing_autotune_summaries(output_root: str) -> list[str]:
    root = Path(output_root)
    if not root.exists():
        return []
    return sorted(str(p) for p in root.glob("run_*/autotune_summary.json"))


def poll_autotune_task() -> dict[str, Any] | None:
    task = st.session_state.get(AUTOTUNE_TASK_KEY)
    if not task:
        return None
    if task.get("status") != "running":
        return task
    proc = task.get("process")
    if proc is None:
        task["status"] = "failed"
        task["error"] = "ä»»åŠ¡è¿›ç¨‹ä¸¢å¤±"
        st.session_state[AUTOTUNE_TASK_KEY] = task
        return task
    return_code = proc.poll()
    if return_code is None:
        return task
    task["returncode"] = return_code
    task["status"] = "success" if return_code == 0 else "failed"
    task["summary_path"] = extract_marker(task["log_path"], "AUTOTUNE_SUMMARY_PATH")
    task["report_path"] = extract_marker(task["log_path"], "AUTOTUNE_REPORT_PATH")
    st.session_state[AUTOTUNE_TASK_KEY] = task
    return task


def load_autotune_summary(summary_path: str) -> dict[str, Any]:
    with open(summary_path, "r", encoding="utf-8") as f:
        return json.load(f)


def autotune_summary_to_df(summary: dict[str, Any]) -> pd.DataFrame:
    rows: list[dict[str, Any]] = []
    for video in summary.get("videos", []):
        video_path = video.get("input")
        for encoder, encoder_data in video.get("encoders", {}).items():
            recommendation = encoder_data.get("recommendation")
            if recommendation:
                rows.append(
                    {
                        "è§†é¢‘": video_path,
                        "ç¼–ç å™¨": encoder,
                        "æ¨è CRF": recommendation.get("crf"),
                        "VMAF": recommendation.get("vmaf_mean"),
                        "å¤§å°(MB)": recommendation.get("output_size_mb"),
                        "å‹ç¼©æ¯”(%)": recommendation.get("compression_ratio"),
                        "é˜ˆå€¼æ˜¯å¦æ»¡è¶³": not recommendation.get("threshold_unmet", True),
                        "æ¥æºé˜¶æ®µ": recommendation.get("source_stage"),
                    }
                )
            else:
                rows.append(
                    {
                        "è§†é¢‘": video_path,
                        "ç¼–ç å™¨": encoder,
                        "æ¨è CRF": None,
                        "VMAF": None,
                        "å¤§å°(MB)": None,
                        "å‹ç¼©æ¯”(%)": None,
                        "é˜ˆå€¼æ˜¯å¦æ»¡è¶³": False,
                        "æ¥æºé˜¶æ®µ": None,
                    }
                )
    return pd.DataFrame(rows)


def render_autotune_summary(summary_path: str) -> None:
    if not summary_path or not os.path.exists(summary_path):
        st.warning("æœªæ‰¾åˆ°è‡ªåŠ¨ç­›é€‰ç»“æœ summary æ–‡ä»¶ã€‚")
        return
    try:
        summary = load_autotune_summary(summary_path)
    except Exception as exc:  # noqa: BLE001
        st.error(f"è¯»å– summary å¤±è´¥: {exc}")
        return

    st.success(f"å·²åŠ è½½ç»“æœ: {summary_path}")
    stats = summary.get("stats", {})
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("è§†é¢‘æ•°", stats.get("videos_total", 0))
    with col2:
        st.metric("æˆåŠŸè§†é¢‘æ•°", stats.get("videos_succeeded", 0))
    with col3:
        st.metric(
            "æˆåŠŸæ¨èæ•°",
            f"{stats.get('successful_recommendations', 0)}/{stats.get('recommendations_total', 0)}",
        )

    df = autotune_summary_to_df(summary)
    if not df.empty:
        st.dataframe(df, use_container_width=True)

    st.subheader("æ¨èåŒºé—´")
    range_rows: list[dict[str, Any]] = []
    for encoder, value in summary.get("encoder_recommendation_ranges", {}).items():
        if not value:
            range_rows.append({"ç¼–ç å™¨": encoder, "æ¨èåŒºé—´": "æ— "})
            continue
        range_rows.append(
            {
                "ç¼–ç å™¨": encoder,
                "æ¨èåŒºé—´": f"CRF {int(value['min_crf'])} ~ {int(value['max_crf'])}",
            }
        )
    if range_rows:
        st.table(pd.DataFrame(range_rows))


def start_autotune_task(
    *,
    inputs: list[str],
    encoders: list[str],
    target_vmaf: float,
    coarse_duration: int,
    coarse_scale: int,
    output_root: str,
    jobs: int,
    strict_mode: bool,
    vmaf_threads: int,
    vmaf_io_mode: str,
) -> None:
    root = Path(output_root)
    root.mkdir(parents=True, exist_ok=True)
    task_id = time.strftime("%Y%m%d_%H%M%S")
    log_path = root / f"autotune_task_{task_id}.log"
    cmd = [
        sys.executable,
        "main.py",
        "autotune",
        *inputs,
        "--encoders",
        *encoders,
        "--target-vmaf",
        str(target_vmaf),
        "--coarse-duration",
        str(coarse_duration),
        "--coarse-scale",
        str(coarse_scale),
        "--output",
        output_root,
        "--jobs",
        str(jobs),
        "--strict" if strict_mode else "--no-strict",
        "--vmaf-threads",
        str(vmaf_threads),
        "--vmaf-io-mode",
        vmaf_io_mode,
    ]

    with log_path.open("w", encoding="utf-8") as logfile:
        process = subprocess.Popen(
            cmd,
            cwd=str(Path(__file__).resolve().parent),
            stdout=logfile,
            stderr=subprocess.STDOUT,
        )

    st.session_state[AUTOTUNE_TASK_KEY] = {
        "id": task_id,
        "status": "running",
        "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        "log_path": str(log_path),
        "cmd": cmd,
        "process": process,
        "output_root": output_root,
        "inputs": inputs,
    }


def stop_autotune_task() -> None:
    task = st.session_state.get(AUTOTUNE_TASK_KEY)
    if not task:
        return
    proc = task.get("process")
    if proc and proc.poll() is None:
        proc.terminate()
        try:
            proc.wait(timeout=5)
        except subprocess.TimeoutExpired:
            proc.kill()
    task["status"] = "cancelled"
    st.session_state[AUTOTUNE_TASK_KEY] = task


# ä¾§è¾¹æ  - é…ç½®
st.sidebar.header("é…ç½®")

# æ¨¡å¼é€‰æ‹©
mode = st.sidebar.radio(
    "æ¨¡å¼",
    ["æŸ¥çœ‹ç»“æœ", "è¿è¡Œè¯„ä¼°", "è‡ªåŠ¨ç­›é€‰"],
    index=0,
)

if mode == "æŸ¥çœ‹ç»“æœ":
    st.header("ğŸ“Š æŸ¥çœ‹è¯„ä¼°ç»“æœ")

    result_files = get_existing_results()

    if not result_files:
        st.warning("è¿˜æ²¡æœ‰è¯„ä¼°ç»“æœã€‚è¯·å…ˆè¿è¡Œè¯„ä¼°æˆ–å°†ç»“æœæ–‡ä»¶æ”¾åˆ° results/ ç›®å½•ä¸‹ã€‚")
    else:
        selected_file = st.selectbox(
            "é€‰æ‹©ç»“æœæ–‡ä»¶",
            result_files,
            format_func=lambda x: Path(x).parent.name,
        )

        if selected_file:
            try:
                results = load_results(selected_file)
                df = results_to_dataframe(results)

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æµ‹è¯•æ•°é‡", len(results))
                with col2:
                    st.metric("æœ€é«˜ VMAF", f"{df['VMAF å¹³å‡'].max():.2f}")
                with col3:
                    if "SSIM å¹³å‡" in df.columns and df["SSIM å¹³å‡"].sum() > 0:
                        st.metric("æœ€é«˜ SSIM", f"{df['SSIM å¹³å‡'].max():.4f}")
                    else:
                        st.metric("æœ€é«˜ SSIM", "N/A")
                with col4:
                    st.metric("æœ€å°æ–‡ä»¶", f"{df['æ–‡ä»¶å¤§å° (MB)'].min():.2f} MB")

                st.subheader("ğŸ¯ å››è±¡é™å›¾ï¼šè´¨é‡ vs å‹ç¼©æ¯”")
                st.markdown(
                    """
                > **å¦‚ä½•çœ‹å›¾**ï¼šå·¦ä¸Šè§’æ˜¯æœ€ä½³åŒºåŸŸï¼ˆé«˜è´¨é‡ + å°æ–‡ä»¶ï¼‰ï¼Œå³ä¸‹è§’æ˜¯æœ€å·®åŒºåŸŸã€‚
                > æ¯ä¸ªç‚¹ä»£è¡¨ä¸€ä¸ªæµ‹è¯•é…ç½®ï¼Œç‚¹æ—è¾¹çš„æ ‡ç­¾æ˜¾ç¤ºå‚æ•°å€¼ã€‚
                """
                )
                st.plotly_chart(plot_quadrant(df), use_container_width=True)

                st.subheader("ğŸ“ˆ æŒ‡æ ‡ vs è´¨é‡å‚æ•°")
                available_metrics = []
                for metric_name, config in METRIC_OPTIONS.items():
                    if config["col"] in df.columns and df[config["col"]].sum() > 0:
                        available_metrics.append(metric_name)

                if available_metrics:
                    selected_metric = st.selectbox(
                        "é€‰æ‹©è¦æŸ¥çœ‹çš„æŒ‡æ ‡",
                        available_metrics,
                        index=0,
                    )
                    st.plotly_chart(
                        plot_metric_vs_param(df, selected_metric),
                        use_container_width=True,
                    )
                else:
                    st.warning("æ²¡æœ‰å¯ç”¨çš„æŒ‡æ ‡æ•°æ®")

                st.subheader("ğŸ“‰ VMAF vs æ–‡ä»¶å¤§å°")
                st.plotly_chart(plot_vmaf_vs_size(df), use_container_width=True)

                st.subheader("âš¡ å‹ç¼©æ•ˆç‡")
                st.plotly_chart(plot_compression_efficiency(df), use_container_width=True)

                st.subheader("ğŸ“‹ è¯¦ç»†æ•°æ®")
                format_dict = {
                    "VMAF å¹³å‡": "{:.2f}",
                    "VMAF æœ€å°": "{:.2f}",
                    "VMAF æœ€å¤§": "{:.2f}",
                    "PSNR-HVS å¹³å‡": "{:.2f}",
                    "PSNR-HVS æœ€å°": "{:.2f}",
                    "PSNR-HVS æœ€å¤§": "{:.2f}",
                    "SSIM å¹³å‡": "{:.4f}",
                    "SSIM æœ€å°": "{:.4f}",
                    "SSIM æœ€å¤§": "{:.4f}",
                    "MS-SSIM å¹³å‡": "{:.4f}",
                    "MS-SSIM æœ€å°": "{:.4f}",
                    "MS-SSIM æœ€å¤§": "{:.4f}",
                    "SNR å¹³å‡ (dB)": "{:.2f}",
                    "SNR æœ€å° (dB)": "{:.2f}",
                    "SNR æœ€å¤§ (dB)": "{:.2f}",
                    "æ–‡ä»¶å¤§å° (MB)": "{:.2f}",
                    "å‹ç¼©æ¯” (%)": "{:.2f}",
                    "ç¼–ç è€—æ—¶ (ç§’)": "{:.2f}",
                }
                format_dict = {k: v for k, v in format_dict.items() if k in df.columns}
                st.dataframe(df.style.format(format_dict), use_container_width=True)

                st.subheader("ğŸ¯ æœ€ä¼˜æ¨è")
                high_quality = df[df["VMAF å¹³å‡"] >= 90]
                if not high_quality.empty:
                    best = high_quality.loc[high_quality["æ–‡ä»¶å¤§å° (MB)"].idxmin()]
                    recommendation = (
                        f"æ¨èé…ç½®ï¼ˆVMAF â‰¥ 90 ä¸­æœ€å°æ–‡ä»¶ï¼‰: "
                        f"**{best['ç¼–ç å™¨']}**, å‚æ•°å€¼ **{best['å‚æ•°å€¼']}**, "
                        f"VMAF **{best['VMAF å¹³å‡']:.2f}**"
                    )
                    if "SSIM å¹³å‡" in best and best["SSIM å¹³å‡"] > 0:
                        recommendation += f", SSIM **{best['SSIM å¹³å‡']:.4f}**"
                    if "SNR å¹³å‡ (dB)" in best and best["SNR å¹³å‡ (dB)"] > 0:
                        recommendation += f", SNR **{best['SNR å¹³å‡ (dB)']:.2f} dB**"
                    recommendation += f", å¤§å° **{best['æ–‡ä»¶å¤§å° (MB)']:.2f} MB**"
                    st.success(recommendation)
                else:
                    st.info("æ²¡æœ‰ VMAF â‰¥ 90 çš„é…ç½®ï¼Œè¯·å°è¯•æ›´é«˜çš„è´¨é‡å‚æ•°")

            except Exception as e:  # noqa: BLE001
                st.error(f"åŠ è½½ç»“æœå¤±è´¥: {e}")

elif mode == "è¿è¡Œè¯„ä¼°":
    st.header("ğŸš€ è¿è¡Œè¯„ä¼°")

    video_path = st.text_input(
        "è§†é¢‘æ–‡ä»¶è·¯å¾„",
        placeholder="/path/to/video.mp4",
    )

    selected_encoders = st.multiselect(
        "é€‰æ‹©ç¼–ç å™¨",
        list(ENCODERS.keys()),
        default=["hevc"],
        format_func=lambda x: ENCODERS[x].name,
    )

    st.subheader("å‚æ•°é…ç½®")

    encoder_params = {}
    for encoder_key in selected_encoders:
        config = ENCODERS[encoder_key]
        st.markdown(f"**{config.name}** (`-{config.param_name}`)")

        col1, col2, col3 = st.columns(3)
        with col1:
            start = st.number_input(
                "èµ·å§‹å€¼",
                min_value=0,
                max_value=100,
                value=config.param_range[0],
                key=f"{encoder_key}_start",
            )
        with col2:
            end = st.number_input(
                "ç»“æŸå€¼",
                min_value=0,
                max_value=100,
                value=config.param_range[1],
                key=f"{encoder_key}_end",
            )
        with col3:
            step = st.number_input(
                "æ­¥é•¿",
                min_value=1,
                max_value=20,
                value=5,
                key=f"{encoder_key}_step",
            )

        encoder_params[encoder_key] = (int(start), int(end), int(step))

    if st.button("å¼€å§‹è¯„ä¼°", type="primary", disabled=not video_path or not selected_encoders):
        if not os.path.exists(video_path):
            st.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        else:
            input_name = Path(video_path).stem
            output_dir = os.path.join("results", input_name)
            os.makedirs(os.path.join(output_dir, "encoded"), exist_ok=True)

            results = []
            total_tasks = sum(
                len(range(start, end + 1, step))
                for start, end, step in encoder_params.values()
            )

            progress_bar = st.progress(0)
            status_text = st.empty()
            current_task = 0

            for encoder_key in selected_encoders:
                start, end, step = encoder_params[encoder_key]
                config = ENCODERS[encoder_key]

                for param_value in range(start, end + 1, step):
                    current_task += 1
                    progress = current_task / total_tasks
                    progress_bar.progress(progress)
                    status_text.text(
                        f"æ­£åœ¨å¤„ç†: {config.name}, {config.param_name}={param_value} "
                        f"({current_task}/{total_tasks})"
                    )

                    try:
                        result = run_single_benchmark(
                            video_path, output_dir, encoder_key, param_value
                        )
                        results.append(result)
                    except Exception as e:  # noqa: BLE001
                        st.warning(f"ç¼–ç å¤±è´¥ ({encoder_key}, {param_value}): {e}")

            if results:
                results_path = os.path.join(output_dir, "results.json")
                save_results(results, results_path)
                progress_bar.progress(1.0)
                status_text.text("è¯„ä¼°å®Œæˆï¼")
                st.success(f"è¯„ä¼°å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° {results_path}")
                st.info("åˆ‡æ¢åˆ°ã€ŒæŸ¥çœ‹ç»“æœã€æ¨¡å¼æŸ¥çœ‹è¯¦ç»†å›¾è¡¨")
            else:
                st.error("æ²¡æœ‰æˆåŠŸçš„è¯„ä¼°ç»“æœ")

else:
    st.header("ğŸ¤– è‡ªåŠ¨ç­›é€‰")
    st.caption("ä¸¤é˜¶æ®µç²—åˆ°ç»†ï¼šå…ˆçŸ­ç‰‡ç²—æ‰«é”åŒºé—´ï¼Œå†å…¨ç‰‡ç²¾æ‰«ã€‚")

    task = poll_autotune_task()

    input_mode = st.radio("è§†é¢‘æ¥æº", ["ç›®å½•æ‰«æ", "æ‰‹å·¥è¾“å…¥"], horizontal=True)
    if input_mode == "ç›®å½•æ‰«æ":
        source_dir = st.text_input("è§†é¢‘ç›®å½•", value=".")
        discovered_videos = discover_videos(source_dir)
        st.caption(f"å‘ç° {len(discovered_videos)} ä¸ªè§†é¢‘æ–‡ä»¶")
        selected_inputs = discovered_videos
    else:
        manual_inputs = st.text_area(
            "è§†é¢‘è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
            placeholder="/path/to/sample1.mp4\n/path/to/sample2.mp4",
            height=120,
        )
        selected_inputs = [line.strip() for line in manual_inputs.splitlines() if line.strip()]

    if selected_inputs:
        st.write("å¾…å¤„ç†è§†é¢‘:")
        for path in selected_inputs:
            st.code(path)

    col1, col2 = st.columns(2)
    with col1:
        target_vmaf = st.number_input("ç›®æ ‡ VMAF", min_value=50.0, max_value=100.0, value=95.0)
        coarse_duration = st.number_input("ç²—æ‰«æ—¶é•¿ï¼ˆç§’ï¼‰", min_value=1, max_value=30, value=10)
        coarse_scale = st.number_input("ç²—æ‰«å®½åº¦", min_value=160, max_value=3840, value=1280)
    with col2:
        autotune_encoders = st.multiselect(
            "ç¼–ç å™¨",
            list(ENCODERS.keys()),
            default=["hevc", "av1"],
            format_func=lambda x: ENCODERS[x].name,
        )
        jobs = st.number_input("å¹¶å‘ä»»åŠ¡æ•°", min_value=1, max_value=8, value=1)
        strict_mode = st.checkbox("ä¸¥æ ¼æ¨¡å¼", value=False)
        vmaf_threads = st.number_input(
            "VMAF çº¿ç¨‹æ•°",
            min_value=1,
            max_value=max(1, os.cpu_count() or 1),
            value=max(1, os.cpu_count() or 1),
        )
        vmaf_io_mode = st.selectbox(
            "VMAF I/O æ¨¡å¼",
            ["auto", "libvmaf", "fifo", "file"],
            index=0,
        )

    output_root = st.text_input("è¾“å‡ºç›®å½•", value="results_autotune")

    task_running = bool(task and task.get("status") == "running")
    start_disabled = task_running or not selected_inputs or not autotune_encoders
    if st.button("å¯åŠ¨è‡ªåŠ¨ç­›é€‰", type="primary", disabled=start_disabled):
        start_autotune_task(
            inputs=selected_inputs,
            encoders=autotune_encoders,
            target_vmaf=float(target_vmaf),
            coarse_duration=int(coarse_duration),
            coarse_scale=int(coarse_scale),
            output_root=output_root,
            jobs=int(jobs),
            strict_mode=strict_mode,
            vmaf_threads=int(vmaf_threads),
            vmaf_io_mode=vmaf_io_mode,
        )
        st.rerun()

    if task:
        st.subheader("ä»»åŠ¡çŠ¶æ€")
        status = task.get("status")
        st.write(f"- ä»»åŠ¡ ID: `{task.get('id')}`")
        st.write(f"- çŠ¶æ€: `{status}`")
        st.write(f"- æ—¥å¿—: `{task.get('log_path')}`")

        if status == "running":
            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("å–æ¶ˆä»»åŠ¡"):
                    stop_autotune_task()
                    st.rerun()
            with col_b:
                st.button("ç«‹å³åˆ·æ–°", on_click=st.rerun)

        log_tail = tail_file(task.get("log_path", ""), lines=100)
        st.text_area("ä»»åŠ¡æ—¥å¿—ï¼ˆæœ€è¿‘ 100 è¡Œï¼‰", log_tail, height=280)

        if status in {"success", "failed", "cancelled"}:
            if status == "success":
                st.success("ä»»åŠ¡å·²å®Œæˆã€‚")
            elif status == "failed":
                st.error(f"ä»»åŠ¡å¤±è´¥ï¼ˆexit={task.get('returncode')}ï¼‰ã€‚")
            else:
                st.warning("ä»»åŠ¡å·²å–æ¶ˆã€‚")

            summary_path = task.get("summary_path")
            report_path = task.get("report_path")
            if report_path:
                st.write(f"æŠ¥å‘Š: `{report_path}`")
            if summary_path:
                render_autotune_summary(summary_path)
            else:
                st.info("æ—¥å¿—ä¸­å°šæœªè§£æåˆ° summary è·¯å¾„ã€‚")

        if status == "running":
            st.info("ä»»åŠ¡è¿›è¡Œä¸­ï¼Œé¡µé¢æ¯ 2 ç§’è‡ªåŠ¨åˆ·æ–°ã€‚")
            time.sleep(2)
            st.rerun()

    st.subheader("å†å²ç»“æœ")
    existing_summaries = get_existing_autotune_summaries(output_root)
    if existing_summaries:
        selected_summary = st.selectbox(
            "é€‰æ‹©å†å² summary",
            existing_summaries,
            format_func=lambda p: str(Path(p).parent.name),
        )
        if selected_summary:
            render_autotune_summary(selected_summary)
    else:
        st.caption("å½“å‰è¾“å‡ºç›®å½•è¿˜æ²¡æœ‰å†å² summaryã€‚")


st.markdown("---")
st.markdown("ğŸ’¡ **æç¤º**: å¤§æ‰¹é‡ç­›é€‰å»ºè®®ç›´æ¥ç”¨ `python main.py autotune ...`ã€‚")
